# Q_GP_transformer
This is a completion transformer based on the model described in the paper "Attention is all you need"  [2017]
